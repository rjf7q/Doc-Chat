{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oSd22v40nUD",
        "outputId": "11677353-7bfc-4dea-c380-969848dc0c6c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain_community in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (0.3.18)\n",
            "Requirement already satisfied: langchain_text_splitters in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (0.3.6)\n",
            "Requirement already satisfied: langchain_openai in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (0.3.7)\n",
            "Requirement already satisfied: langchain_chroma in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (0.2.2)\n",
            "Requirement already satisfied: gradio in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (4.44.1)\n",
            "Requirement already satisfied: python-dotenv in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (0.21.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.37 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain_community) (0.3.39)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.19 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain_community) (0.3.19)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain_community) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain_community) (3.11.10)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain_community) (9.0.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain_community) (2.8.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain_community) (0.3.10)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain_openai) (1.65.3)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain_openai) (0.9.0)\n",
            "Requirement already satisfied: chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain_chroma) (0.6.3)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from gradio) (4.8.0)\n",
            "Requirement already satisfied: fastapi<1.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from gradio) (0.115.8)\n",
            "Requirement already satisfied: ffmpy in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.3.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from gradio) (1.3.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from gradio) (0.28.0)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from gradio) (3.1.5)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from gradio) (2.1.3)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from gradio) (3.9.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from gradio) (2.2.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from gradio) (10.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from gradio) (2.10.3)\n",
            "Requirement already satisfied: pydub in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from gradio) (0.9.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from gradio) (2.3.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from gradio) (0.34.0)\n",
            "Requirement already satisfied: fsspec in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from gradio-client==1.3.0->gradio) (2024.12.0)\n",
            "Requirement already satisfied: websockets<13.0,>=10.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from gradio-client==1.3.0->gradio) (12.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.0)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: build>=1.0.3 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.2.2.post1)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.7.6)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (3.18.1)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.19.2)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.30.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.20.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (4.66.5)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (7.7.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.71.0rc2)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (4.3.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (32.0.1)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (5.1.0)\n",
            "Requirement already satisfied: rich>=10.11.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (13.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from fastapi<1.0->gradio) (0.45.3)\n",
            "Requirement already satisfied: certifi in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from huggingface-hub>=0.19.3->gradio) (3.13.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from importlib-resources<7.0,>=1.3->gradio) (3.21.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain-core<1.0.0,>=0.3.37->langchain_community) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from matplotlib~=3.0->gradio) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from matplotlib~=3.0->gradio) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from matplotlib~=3.0->gradio) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from matplotlib~=3.0->gradio) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from matplotlib~=3.0->gradio) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from matplotlib~=3.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from pydantic>=2.0->gradio) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from requests<3,>=2->langchain_community) (2.0.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: click>=8.0.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from typer<1.0,>=0.12->gradio) (1.5.0)\n",
            "Requirement already satisfied: pyproject_hooks in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from build>=1.0.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.2.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.6 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from build>=1.0.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (8.5.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from build>=1.0.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (2.2.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.37->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.17.0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (2.29.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (3.2.2)\n",
            "Requirement already satisfied: durationpy>=0.7 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.9)\n",
            "Requirement already satisfied: coloredlogs in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (5.29.3)\n",
            "Requirement already satisfied: sympy in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.13.3)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.2.18)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.68.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.30.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.30.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.51b0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.51b0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.51b0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.51b0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from opentelemetry-instrumentation==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.17.0)\n",
            "Requirement already satisfied: asgiref~=3.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from posthog>=2.4.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from posthog>=2.4.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (2.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from rich>=10.11.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from rich>=10.11.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (2.19.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.6.4)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.0.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (4.7.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.1.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from sympy->onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.4.8)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain_cohere in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (0.4.2)\n",
            "Requirement already satisfied: cohere<6.0,>=5.12.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain_cohere) (5.14.0)\n",
            "Requirement already satisfied: langchain-community<0.4.0,>=0.3.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain_cohere) (0.3.18)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.27 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain_cohere) (0.3.39)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain_cohere) (2.10.3)\n",
            "Requirement already satisfied: types-pyyaml<7.0.0.0,>=6.0.12.20240917 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain_cohere) (6.0.12.20241230)\n",
            "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from cohere<6.0,>=5.12.0->langchain_cohere) (1.10.0)\n",
            "Requirement already satisfied: httpx>=0.21.2 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from cohere<6.0,>=5.12.0->langchain_cohere) (0.28.1)\n",
            "Requirement already satisfied: httpx-sse==0.4.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from cohere<6.0,>=5.12.0->langchain_cohere) (0.4.0)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from cohere<6.0,>=5.12.0->langchain_cohere) (2.27.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from cohere<6.0,>=5.12.0->langchain_cohere) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from cohere<6.0,>=5.12.0->langchain_cohere) (0.20.1)\n",
            "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from cohere<6.0,>=5.12.0->langchain_cohere) (2.32.0.20250301)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from cohere<6.0,>=5.12.0->langchain_cohere) (4.12.2)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.19 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_cohere) (0.3.19)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_cohere) (2.0.38)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_cohere) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_cohere) (3.11.10)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_cohere) (9.0.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_cohere) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_cohere) (2.8.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_cohere) (0.3.10)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_cohere) (1.26.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain_cohere) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain_cohere) (24.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from pydantic<3,>=2->langchain_cohere) (0.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_cohere) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_cohere) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_cohere) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_cohere) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_cohere) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_cohere) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_cohere) (1.18.0)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_cohere) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_cohere) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_cohere) (0.9.0)\n",
            "Requirement already satisfied: anyio in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from httpx>=0.21.2->cohere<6.0,>=5.12.0->langchain_cohere) (4.8.0)\n",
            "Requirement already satisfied: certifi in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from httpx>=0.21.2->cohere<6.0,>=5.12.0->langchain_cohere) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from httpx>=0.21.2->cohere<6.0,>=5.12.0->langchain_cohere) (1.0.7)\n",
            "Requirement already satisfied: idna in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from httpx>=0.21.2->cohere<6.0,>=5.12.0->langchain_cohere) (3.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from httpcore==1.*->httpx>=0.21.2->cohere<6.0,>=5.12.0->langchain_cohere) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain_cohere) (3.0.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain<1.0.0,>=0.3.19->langchain-community<0.4.0,>=0.3.0->langchain_cohere) (0.3.6)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_cohere) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_cohere) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_cohere) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain_cohere) (0.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from requests<3.0.0,>=2.0.0->cohere<6.0,>=5.12.0->langchain_cohere) (2.0.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from requests<3.0.0,>=2.0.0->cohere<6.0,>=5.12.0->langchain_cohere) (2.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from tokenizers<1,>=0.15->cohere<6.0,>=5.12.0->langchain_cohere) (0.28.0)\n",
            "Requirement already satisfied: filelock in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.12.0->langchain_cohere) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.12.0->langchain_cohere) (2024.12.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.12.0->langchain_cohere) (4.66.5)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_cohere) (1.0.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from anyio->httpx>=0.21.2->cohere<6.0,>=5.12.0->langchain_cohere) (1.2.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/envs/dev/lib/python3.9/site-packages (from anyio->httpx>=0.21.2->cohere<6.0,>=5.12.0->langchain_cohere) (1.3.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install langchain_community langchain_text_splitters langchain_openai langchain_chroma gradio python-dotenv\n",
        "%pip install langchain_cohere"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJE4OzG01XNB",
        "outputId": "4d4b2b54-db9f-472d-8ce6-5c739635ab43"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "\n",
        "# # Mount Google Drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# # Define the Google Drive path where your documents are stored\n",
        "# google_drive_path = '/content/drive/MyDrive/local_rag/data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DATA_PATH = r\"data\"\n",
        "CHROMA_PATH = r\"chroma_db\"\n",
        "import os\n",
        "\n",
        "# import the .env file\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "# print(os.environ.get(\"COHERE_API_KEY\")) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "lX1fyZRVDM1d"
      },
      "outputs": [],
      "source": [
        "from langchain_chroma import Chroma\n",
        "import gradio as gr\n",
        "from langchain.embeddings import SentenceTransformerEmbeddings\n",
        "\n",
        "# Load the embedding model\n",
        "embeddings_model = SentenceTransformerEmbeddings(model_name=\"all-mpnet-base-v2\")\n",
        "\n",
        "# Use the model with LangChain as before\n",
        "vector_store = Chroma(\n",
        "    collection_name=\"example_collection\",\n",
        "    embedding_function=embeddings_model,\n",
        "    persist_directory=CHROMA_PATH,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCcxOMtIFylR",
        "outputId": "79da4ec7-53cd-46bf-af4d-1ebd2b5115eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Document(id='98369a59-fdd6-4571-8f37-2c076971e0b0', metadata={'creationdate': '', 'creator': 'Google', 'page': 16, 'page_label': '17', 'producer': 'PyPDF', 'source': 'data/M11.1__Introduction_to_Machine_Learning.pdf', 'title': 'M11.1: Introduction to Machine Learning', 'total_pages': 74}, page_content='2. It measures how closely that action \\ntook it to completing a task.\\n1. The agent observes \\nits environment and \\ntakes an action.\\nEnvironment\\nAgent\\nState\\nReward\\nAction'), Document(id='1843a1d7-1aeb-48e4-b87f-3287cfe3d0cb', metadata={'creationdate': '', 'creator': 'Google', 'page': 18, 'page_label': '19', 'producer': 'PyPDF', 'source': 'data/M1.2_ The Impact of Machine Learning.pdf', 'title': 'M1.2: The Impact of Machine Learning', 'total_pages': 50}, page_content='— Merritt, R. 2022. What is a transformer model? [Blog, 25 March].\\nAvailable: https://blogs.nvidia.com/blog/2022/03/25/what-is-a-transformer-model/ [2023, April 5].\\n“A transformer model is a neural network that \\nlearns context and thus meaning by tracking'), Document(id='4660cdf5-5dbc-4cb2-8503-ba74f4a17fa9', metadata={'creationdate': '', 'creator': 'Google', 'page': 26, 'page_label': '27', 'producer': 'PyPDF', 'source': 'data/M18.3_RBMs_and_Recommendation_Systems.pdf', 'title': 'M18.3: RBMs and Recommendation Systems', 'total_pages': 59}, page_content='posts like the ones they gave attention to.\\nExplicitly, such as when a user interacts with \\nthe system and gives an item a rating, likes a \\nproduct, downvotes a post, or uses an emoji \\nreaction on a Facebook post. The ratings we \\nexplored in the music example demonstrate \\nexplicit preferences.'), Document(id='7da19ec0-def0-4a4b-ad5c-11d05daaf559', metadata={'creationdate': '', 'creator': 'Google', 'page': 26, 'page_label': '27', 'producer': 'PyPDF', 'source': 'data/M18.3_RBMs_and_Recommendation_Systems.pdf', 'title': 'M18.3: RBMs and Recommendation Systems', 'total_pages': 59}, page_content='spends a few seconds reading a post \\nrather than scrolling right past it. All of \\nthese examples could indicate that the \\nuser is interested in more videos, ads, or \\nposts like the ones they gave attention to.\\nExplicitly, such as when a user interacts with'), Document(id='75926332-04a9-4458-927a-bb648139bf98', metadata={'creationdate': '', 'creator': 'Google', 'page': 27, 'page_label': '28', 'producer': 'PyPDF', 'source': 'data/M20.3_Advanced_NLP_Techniques_Topic_Modeling_andRNN.pdf', 'title': 'M20.3: Advanced NLP Techniques: Topic Modeling and RNN', 'total_pages': 53}, page_content='What Are RNNs Used For?\\nSend $50 to Allison to be delivered \\ntoday from my check account\\nI understand, Tom. I’d be happy to help \\nyou with that')]\n",
            "[Document(id='fa713094-e1ab-4f2a-bb12-0ddc88e8b8ca', metadata={'creationdate': '', 'creator': 'Google', 'page': 30, 'page_label': '31', 'producer': 'PyPDF', 'source': 'data/M6.1__Sourcing_Data_for_AI_Projects.pdf', 'title': 'M6.1: Sourcing Data for AI Projects', 'total_pages': 72}, page_content='Client–Server Model\\nThe Client–Server Model is a structure that outlines the relationship and ﬂow \\nof communication between two components: a client and a server.\\nResponse\\n</>\\nClient Request\\n</>\\nServerWeb Browser\\n(Client)'), Document(id='261c0db3-6913-40ee-a2e0-a0b76437d925', metadata={'creationdate': '', 'creator': 'Google', 'page': 32, 'page_label': '33', 'producer': 'PyPDF', 'source': 'data/M6.1__Sourcing_Data_for_AI_Projects.pdf', 'title': 'M6.1: Sourcing Data for AI Projects', 'total_pages': 72}, page_content='The Client–Server Model\\nClients Server\\nClients submit requests to servers and \\nthen wait for a response from the server.\\nClients and servers are able to \\ncommunicate because of HTTP \\nprotocols. HTTP protocols are policies \\nfor the transmission of data between'), Document(id='5bbb1072-a9fd-47fa-981e-99eeed28956f', metadata={'creationdate': '', 'creator': 'Google', 'page': 17, 'page_label': '18', 'producer': 'PyPDF', 'source': 'data/M20.1_Introduction_to_Natural_Language_Processing(NLP).pdf', 'title': 'M20.1: Introduction to Natural Language Processing (NLP)', 'total_pages': 52}, page_content='What is a Corpus?'), Document(id='0542266b-9d10-48ed-8f94-40824caba9cf', metadata={'creationdate': '', 'creator': 'Google', 'page': 32, 'page_label': '33', 'producer': 'PyPDF', 'source': 'data/M6.1__Sourcing_Data_for_AI_Projects.pdf', 'title': 'M6.1: Sourcing Data for AI Projects', 'total_pages': 72}, page_content='protocols. HTTP protocols are policies \\nfor the transmission of data between \\nclient and server. HTTP protocols allow \\nusers to execute server functions and \\nclients and servers to exchange data.\\nInternet'), Document(id='506c9198-52c1-4ac7-b00f-469e7b03792f', metadata={'creationdate': '', 'creator': 'Google', 'page': 29, 'page_label': '30', 'producer': 'PyPDF', 'source': 'data/M6.1__Sourcing_Data_for_AI_Projects.pdf', 'title': 'M6.1: Sourcing Data for AI Projects', 'total_pages': 72}, page_content='The Client–Server Model')]\n"
          ]
        }
      ],
      "source": [
        "num_results = 5\n",
        "\n",
        "retriever = vector_store.as_retriever(search_kwargs={'k': num_results})\n",
        "\n",
        "docs = retriever.invoke(\"What is attention\")\n",
        "print(docs)\n",
        "\n",
        "docs = retriever.invoke(\"What is communication\")\n",
        "print(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOw2D_uRDdW4",
        "outputId": "4e556c35-8e26-4ee7-a33a-5106337c48c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Document(id='98369a59-fdd6-4571-8f37-2c076971e0b0', metadata={'creationdate': '', 'creator': 'Google', 'page': 16, 'page_label': '17', 'producer': 'PyPDF', 'source': 'data/M11.1__Introduction_to_Machine_Learning.pdf', 'title': 'M11.1: Introduction to Machine Learning', 'total_pages': 74}, page_content='2. It measures how closely that action \\ntook it to completing a task.\\n1. The agent observes \\nits environment and \\ntakes an action.\\nEnvironment\\nAgent\\nState\\nReward\\nAction'), Document(id='1843a1d7-1aeb-48e4-b87f-3287cfe3d0cb', metadata={'creationdate': '', 'creator': 'Google', 'page': 18, 'page_label': '19', 'producer': 'PyPDF', 'source': 'data/M1.2_ The Impact of Machine Learning.pdf', 'title': 'M1.2: The Impact of Machine Learning', 'total_pages': 50}, page_content='— Merritt, R. 2022. What is a transformer model? [Blog, 25 March].\\nAvailable: https://blogs.nvidia.com/blog/2022/03/25/what-is-a-transformer-model/ [2023, April 5].\\n“A transformer model is a neural network that \\nlearns context and thus meaning by tracking'), Document(id='4660cdf5-5dbc-4cb2-8503-ba74f4a17fa9', metadata={'creationdate': '', 'creator': 'Google', 'page': 26, 'page_label': '27', 'producer': 'PyPDF', 'source': 'data/M18.3_RBMs_and_Recommendation_Systems.pdf', 'title': 'M18.3: RBMs and Recommendation Systems', 'total_pages': 59}, page_content='posts like the ones they gave attention to.\\nExplicitly, such as when a user interacts with \\nthe system and gives an item a rating, likes a \\nproduct, downvotes a post, or uses an emoji \\nreaction on a Facebook post. The ratings we \\nexplored in the music example demonstrate \\nexplicit preferences.'), Document(id='7da19ec0-def0-4a4b-ad5c-11d05daaf559', metadata={'creationdate': '', 'creator': 'Google', 'page': 26, 'page_label': '27', 'producer': 'PyPDF', 'source': 'data/M18.3_RBMs_and_Recommendation_Systems.pdf', 'title': 'M18.3: RBMs and Recommendation Systems', 'total_pages': 59}, page_content='spends a few seconds reading a post \\nrather than scrolling right past it. All of \\nthese examples could indicate that the \\nuser is interested in more videos, ads, or \\nposts like the ones they gave attention to.\\nExplicitly, such as when a user interacts with'), Document(id='75926332-04a9-4458-927a-bb648139bf98', metadata={'creationdate': '', 'creator': 'Google', 'page': 27, 'page_label': '28', 'producer': 'PyPDF', 'source': 'data/M20.3_Advanced_NLP_Techniques_Topic_Modeling_andRNN.pdf', 'title': 'M20.3: Advanced NLP Techniques: Topic Modeling and RNN', 'total_pages': 53}, page_content='What Are RNNs Used For?\\nSend $50 to Allison to be delivered \\ntoday from my check account\\nI understand, Tom. I’d be happy to help \\nyou with that')]\n",
            "2. It measures how closely that action \n",
            "took it to completing a task.\n",
            "1. The agent observes \n",
            "its environment and \n",
            "takes an action.\n",
            "Environment\n",
            "Agent\n",
            "State\n",
            "Reward\n",
            "Action\n",
            "— Merritt, R. 2022. What is a transformer model? [Blog, 25 March].\n",
            "Available: https://blogs.nvidia.com/blog/2022/03/25/what-is-a-transformer-model/ [2023, April 5].\n",
            "“A transformer model is a neural network that \n",
            "learns context and thus meaning by tracking\n",
            "posts like the ones they gave attention to.\n",
            "Explicitly, such as when a user interacts with \n",
            "the system and gives an item a rating, likes a \n",
            "product, downvotes a post, or uses an emoji \n",
            "reaction on a Facebook post. The ratings we \n",
            "explored in the music example demonstrate \n",
            "explicit preferences.\n",
            "spends a few seconds reading a post \n",
            "rather than scrolling right past it. All of \n",
            "these examples could indicate that the \n",
            "user is interested in more videos, ads, or \n",
            "posts like the ones they gave attention to.\n",
            "Explicitly, such as when a user interacts with\n",
            "What Are RNNs Used For?\n",
            "Send $50 to Allison to be delivered \n",
            "today from my check account\n",
            "I understand, Tom. I’d be happy to help \n",
            "you with that\n",
            "[{'source': 'data/M11.1__Introduction_to_Machine_Learning.pdf', 'page_label': '17'}, {'source': 'data/M1.2_ The Impact of Machine Learning.pdf', 'page_label': '19'}, {'source': 'data/M18.3_RBMs_and_Recommendation_Systems.pdf', 'page_label': '27'}, {'source': 'data/M18.3_RBMs_and_Recommendation_Systems.pdf', 'page_label': '27'}, {'source': 'data/M20.3_Advanced_NLP_Techniques_Topic_Modeling_andRNN.pdf', 'page_label': '28'}]\n"
          ]
        }
      ],
      "source": [
        "docs = retriever.invoke(\"What is attention\")\n",
        "print(docs)\n",
        "knowledge = \"\"\n",
        "sources = []\n",
        "for doc in docs:\n",
        "    knowledge += doc.page_content+\"\\n\\n\"\n",
        "    print(doc.page_content)\n",
        "\n",
        "for doc in docs:\n",
        "    sources.append({\"source\":doc.metadata[\"source\"], \"page_label\":doc.metadata[\"page_label\"]})\n",
        "\n",
        "print(sources)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatCohere\n",
        "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import SentenceTransformerEmbeddings\n",
        "\n",
        "# Initialize Cohere LLM\n",
        "llm = ChatCohere(model=\"command-r-plus-08-2024\")\n",
        "\n",
        "# Load the embedding model\n",
        "embeddings_model = SentenceTransformerEmbeddings(model_name=\"all-mpnet-base-v2\")\n",
        "\n",
        "# Initialize Vector Store\n",
        "vector_store = Chroma(\n",
        "    collection_name=\"example_collection\",\n",
        "    embedding_function=embeddings_model,\n",
        "    persist_directory=CHROMA_PATH,\n",
        ")\n",
        "\n",
        "# Set up retriever\n",
        "num_results = 5\n",
        "retriever = vector_store.as_retriever(search_kwargs={'k': num_results})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def stream_response(message, history, skipSources=False):\n",
        "    \"\"\"Handles chatbot conversation in Gradio.\"\"\"\n",
        "    partial_message = \"\"\n",
        "    # Convert Gradio history to LangChain format\n",
        "    chat_history = [SystemMessage(content=\"You are a helpful assistant. Answer based on the provided knowledge.\")]\n",
        "    for user_msg, bot_msg in history:\n",
        "        chat_history.append(HumanMessage(content=user_msg))\n",
        "        chat_history.append(AIMessage(content=bot_msg))\n",
        "\n",
        "    # Retrieve relevant documents\n",
        "    docs = retriever.invoke(message)\n",
        "\n",
        "    # Format retrieved knowledge\n",
        "    knowledge = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
        "    sources = \"\\n\".join([f\"- **Document**: {doc.metadata['source']}, **Page**: {doc.metadata.get('page_label', 'N/A')}\" for doc in docs])\n",
        "    \n",
        "\n",
        "    # Construct the prompt\n",
        "    rag_prompt = f\"\"\"\n",
        "    You are an assistant that answers questions based solely on the provided knowledge.\n",
        "    If the knowledge does not contain the answer, say you don't know.\n",
        "    \n",
        "    The knowledge:\n",
        "    {knowledge}\n",
        "    \"\"\"\n",
        "\n",
        "    # Append user query\n",
        "    chat_history.append(HumanMessage(content=message))\n",
        "    chat_history.append(AIMessage(content=rag_prompt))\n",
        "\n",
        "\n",
        "    last_chunk = None  # Track last chunk\n",
        "    for response in llm.stream(chat_history):\n",
        "        partial_message += response.content\n",
        "        last_chunk = response.content  # Keep track of the final chunk\n",
        "        yield partial_message  # Send intermediate responses\n",
        "\n",
        "    # Append sources only to the last streamed chunk\n",
        "    if last_chunk:\n",
        "        uncertainty_phrases = [\"I don't know\", \"I'm not sure if I can answer that\", \"I'm sorry\"]\n",
        "        if not skipSources and not any(phrase.lower() in partial_message.lower() for phrase in uncertainty_phrases):\n",
        "            final_response = partial_message + \"\\n\\n\"+ f\"Sources:\\n\" + sources \n",
        "        else:\n",
        "            final_response = partial_message \n",
        "        yield final_response \n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'query': 'What is machine learning?',\n",
              "  'expected': 'Machine learning is a field within AI that develops algorithms and models enabling computers to learn and make decisions without explicit programming. It allows machines to analyze data, identify patterns, and make informed decisions with minimal human intervention by training on vast datasets. ML is categorized into three types: Supervised Learning, where algorithms learn from labeled data to make predictions; Unsupervised Learning, where algorithms find patterns in unlabeled data for clustering and anomaly detection; and Reinforcement Learning, where models learn through rewards and penalties to optimize decision-making. Applications include image and speech recognition, NLP, recommendation systems, fraud detection, predictive analytics, and autonomous driving, making ML a key part of modern AI systems.',\n",
              "  'generated': \"I don't know.\"},\n",
              " {'query': 'What is logistic regression?',\n",
              "  'expected': 'Logistic regression is a statistical method used to predict binary outcomes, such as the probability of an event occurring or a category that a data point belongs to. It employs a sigmoid function to convert continuous data into a probability, enabling predictions about binary events or classifications.',\n",
              "  'generated': \"The AI course curriculum covers a range of topics, including:\\n\\n- **Real-world applications of AI**: Understanding how AI is applied in various industries and its benefits.\\n- **GitHub and Command Line**: Students learn to use GitHub, a popular platform for version control and collaboration, and how to interact with it via the command line.\\n- **Project Documentation**: Emphasizing the importance of clear and effective documentation in AI projects.\\n- **Virtual Environment Setup**: Students will be taught how to set up and manage virtual environments, which are essential for creating isolated and reproducible development environments.\\n- **Introduction to AI and ML**: Defining and differentiating between Artificial Intelligence (AI) and Machine Learning (ML), providing a foundational understanding of these key concepts.\\n- **Personal Reflections**: Encouraging students to reflect on their interactions with AI, its importance, and their interests in the field.\\n- **Practical AI Tools**: Hands-on experience with tools like Anaconda, the command line, and GitHub, which are essential for AI development and collaboration.\\n- **Brainstorming and Sector Analysis**: Engaging students in activities to brainstorm about personal AI experiences and investigate AI's impact across different sectors.\\n\\nThe course seems to be designed to provide a comprehensive introduction to AI, covering both theoretical and practical aspects, and encouraging students to explore the field's potential and applications.\"},\n",
              " {'query': 'What is a neural network?',\n",
              "  'expected': 'A neural network is an advanced machine learning model inspired by the human brain, consisting of interconnected artificial neurons organized into input, hidden, and output layers. These networks excel at processing complex, large-scale datasets and are widely used by companies like Google, Facebook, Twitter, and Amazon for various applications. They learn by adjusting connection weights and biases through backpropagation, an iterative process that minimizes prediction errors, enhancing their accuracy and performance over time.',\n",
              "  'generated': \"The AI course curriculum covers a range of topics, including:\\n\\n- **Real-world applications of AI**: Understanding how AI is applied in various industries and its benefits.\\n- **GitHub and Command Line**: Students learn to use GitHub, a popular platform for version control and collaboration, and how to interact with it via the command line.\\n- **Project Documentation**: Emphasizing the importance of clear and effective documentation in AI projects.\\n- **Virtual Environment Setup**: Students will be taught how to set up and manage virtual environments, which are essential for creating isolated and reproducible development environments.\\n- **Introduction to AI and ML**: Defining and differentiating between Artificial Intelligence (AI) and Machine Learning (ML), providing a foundational understanding of these key concepts.\\n- **Personal Reflections**: Encouraging students to reflect on their interactions with AI, its importance, and their interests in the field.\\n- **Practical AI Tools**: Hands-on experience with tools like Anaconda, the command line, and GitHub, which are essential for AI development and collaboration.\\n- **Brainstorming and Sector Analysis**: Engaging students in activities to brainstorm about personal AI experiences and investigate AI's impact across different sectors.\\n\\nThe course seems to be designed to provide a comprehensive introduction to AI, covering both theoretical and practical aspects, and encouraging students to explore the field's potential and applications.\"}]"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "with open('test_cases.json', 'r') as file:\n",
        "    test_cases = json.load(file)\n",
        "\n",
        "test_cases\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "    {\n",
            "        \"query\": \"What is machine learning?\",\n",
            "        \"expected\": \"Machine learning is a field within AI that develops algorithms and models enabling computers to learn and make decisions without explicit programming. It allows machines to analyze data, identify patterns, and make informed decisions with minimal human intervention by training on vast datasets. ML is categorized into three types: Supervised Learning, where algorithms learn from labeled data to make predictions; Unsupervised Learning, where algorithms find patterns in unlabeled data for clustering and anomaly detection; and Reinforcement Learning, where models learn through rewards and penalties to optimize decision-making. Applications include image and speech recognition, NLP, recommendation systems, fraud detection, predictive analytics, and autonomous driving, making ML a key part of modern AI systems.\",\n",
            "        \"generated\": \"Machine learning is a branch of artificial intelligence (AI) that enables computer systems to automatically learn and improve from experience without being explicitly programmed. It focuses on developing algorithms and models that can analyse data, identify patterns, and make predictions or decisions with minimal human intervention.\\n\\nIn machine learning, algorithms are trained using large datasets to recognise and interpret complex data inputs. These algorithms can be supervised, where the model learns from labelled data, or unsupervised, where it identifies patterns in unlabelled data. Reinforcement learning is another approach where the model learns through trial and error, receiving feedback in the form of rewards or penalties.\\n\\nThe goal of machine learning is to develop systems that can generalise from past data and make accurate predictions or decisions in new, unseen situations. This technology has various applications, including image and speech recognition, natural language processing, recommendation systems, autonomous driving, and predictive analytics.\"\n",
            "    },\n",
            "    {\n",
            "        \"query\": \"What is logistic regression?\",\n",
            "        \"expected\": \"Logistic regression is a statistical method used to predict binary outcomes, such as the probability of an event occurring or a category that a data point belongs to. It employs a sigmoid function to convert continuous data into a probability, enabling predictions about binary events or classifications.\",\n",
            "        \"generated\": \"Logistic regression is a statistical method used to predict binary outcomes, such as whether a borrower is likely to be a \\\"good credit\\\" risk or not. It employs a sigmoid function to convert continuous data, like a borrower's payment history, into a probability value between 0 and 1. This function ensures that the predicted probability falls within a reasonable range, making it suitable for binary classification tasks.\\n\\nThe provided knowledge also mentions that a comprehensive logistic regression model should consider multiple factors beyond just payment history to enhance the accuracy of its predictions.\"\n",
            "    },\n",
            "    {\n",
            "        \"query\": \"What is a neural network?\",\n",
            "        \"expected\": \"A neural network is an advanced machine learning model inspired by the human brain, consisting of interconnected artificial neurons organized into input, hidden, and output layers. These networks excel at processing complex, large-scale datasets and are widely used by companies like Google, Facebook, Twitter, and Amazon for various applications. They learn by adjusting connection weights and biases through backpropagation, an iterative process that minimizes prediction errors, enhancing their accuracy and performance over time.\",\n",
            "        \"generated\": \"A neural network is a sophisticated machine learning technique inspired by the human brain's structure and functionality. It consists of multiple layers of nodes, each performing individual computations, similar to how biological neurons work in the brain. These networks are designed to process complex datasets and are widely used by industry leaders like Google, Facebook, Twitter, and Amazon for advanced data analysis.\\n\\nIn essence, a neural network is a set of algorithms that mimic the behaviour of the brain's neurons, allowing machines to learn and make intelligent decisions based on input data.\"\n",
            "    }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Generate responses for each test case\n",
        "for test_case in test_cases:\n",
        "    response_generator = stream_response(test_case[\"query\"], [], True)\n",
        "    generated_response = \"\"\n",
        "    for partial_response in response_generator:\n",
        "        generated_response = partial_response  # Get the final response\n",
        "    test_case[\"generated\"] = generated_response\n",
        "\n",
        "# Save the test cases to a JSON file\n",
        "with open(\"test_cases.json\", \"w\") as file:\n",
        "    json.dump(test_cases, file, indent=4)\n",
        "\n",
        "# Print the test cases\n",
        "print(json.dumps(test_cases, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "QRUpa-m04F-F"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7879\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on public URL: https://01c716bde7e8ee4ab4.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://01c716bde7e8ee4ab4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "with gr.Blocks(css=\"\"\"\n",
        "    body {background-color: #121212; color: #e0e0e0;}\n",
        "    .gradio-container {background-color: #121212;}\n",
        "    .chat-message {border-radius: 10px; padding: 10px; margin: 5px 0; font-size: 20px;}  /* Increased font size */\n",
        "    .chat-message.user {background-color: #1e1e1e; color: #ffffff; text-align: right; font-size: 25px;} /* Bigger font for user */\n",
        "    .chat-message.bot {background-color: #333333; color: #bb86fc; font-weight: bold; font-size: 25px;} /* Bigger font for bot */\n",
        "\"\"\") as demo:\n",
        "    \n",
        "    gr.Markdown(\n",
        "        \"<h1 style='text-align: center; color: #bb86fc;'>💬 Docu-Chat</h2>\",\n",
        "    )\n",
        "\n",
        "    chatbot = gr.ChatInterface(\n",
        "        stream_response,\n",
        "        chatbot=gr.Chatbot(\n",
        "            bubble_full_width=False,\n",
        "            avatar_images=(\"./user.png\", \"./bot.png\"),  # Change avatar images\n",
        "        ),\n",
        "        textbox=gr.Textbox(\n",
        "            placeholder=\"Type your message...\",\n",
        "            container=False,\n",
        "            autoscroll=True,\n",
        "            \n",
        "        ),\n",
        "    )\n",
        "\n",
        "demo.launch(share=True)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dev",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
