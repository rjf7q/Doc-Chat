{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vACFNH74rWFl",
        "outputId": "e973e38a-66ba-4055-c4a2-dba2708fcdcd"
      },
      "outputs": [],
      "source": [
        "%pip install langchain_community langchain_text_splitters langchain_openai langchain_chroma gradio python-dotenv pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLEcArZTsQ-_",
        "outputId": "12b26867-7924-428a-de3c-f4a32cd9cf7d"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "\n",
        "# # Mount Google Drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# # Define the Google Drive path where your documents are stored\n",
        "# google_drive_path = '/content/drive/MyDrive/local_rag/data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_PATH = r\"data\"\n",
        "CHROMA_PATH = r\"chroma_db\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIDvFUgesnRd",
        "outputId": "0bbac479-d99a-450a-b890-010ba6634cbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PDF Files: ['AttentionIsAllyouNeed.pdf', 'bedrock-ug.pdf']\n",
            "DOCX Files: []\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Get a list of all files in the specified folder\n",
        "file_list = os.listdir(DATA_PATH)\n",
        "\n",
        "# Filter the list to only include files with .pdf or .docx extensions\n",
        "pdf_files = [f for f in file_list if f.endswith('.pdf')]\n",
        "docx_files = [f for f in file_list if f.endswith('.docx')]\n",
        "\n",
        "# Example: Print the list of PDF and DOCX files in the folder\n",
        "print(\"PDF Files:\", pdf_files)\n",
        "print(\"DOCX Files:\", docx_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rw5NJ13xcyR",
        "outputId": "37e76925-e2c1-434e-e617-f601e9911817"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/avineetsharma/Project/Columbia/LocalDocuChat\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "current_directory = os.getcwd()\n",
        "print(current_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_chroma import Chroma\n",
        "from uuid import uuid4\n",
        "from langchain.embeddings import SentenceTransformerEmbeddings\n",
        "\n",
        "# import the .env file\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "from uuid import uuid4\n",
        "from langchain.embeddings import SentenceTransformerEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "embeddings_model = SentenceTransformerEmbeddings(model_name=\"all-mpnet-base-v2\")\n",
        "vector_store = Chroma(\n",
        "    collection_name=\"example_collection\",\n",
        "    embedding_function=embeddings_model,\n",
        "    persist_directory=CHROMA_PATH,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def indexed_files(vector_store):\n",
        "    stored_files = set(\n",
        "        [\n",
        "            meta[\"source\"].split(\"/\")[-1]\n",
        "            for meta in vector_store._collection.get(include=[\"metadatas\"])[\"metadatas\"]\n",
        "            if meta and \"source\" in meta\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    print (\"stored_files:\",stored_files)\n",
        "    return stored_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def process_files(vector_store, embeddings_model):\n",
        "    \"\"\"\n",
        "    Processes files in DATA_PATH, adding new files and removing deleted files.\n",
        "    \"\"\"\n",
        "    current_files = set(os.listdir(DATA_PATH))\n",
        "\n",
        "    print (\"current_files:\",current_files)\n",
        "\n",
        "    stored_files = indexed_files(vector_store)\n",
        "\n",
        "\n",
        "    # Find new files\n",
        "    new_files = current_files - stored_files\n",
        "    for filename in new_files:\n",
        "        if filename.endswith(\".pdf\"):\n",
        "            filepath = os.path.join(DATA_PATH, filename)\n",
        "            loader = PyPDFLoader(filepath)\n",
        "            raw_documents = loader.load()\n",
        "\n",
        "            text_splitter = RecursiveCharacterTextSplitter(\n",
        "                chunk_size=300,\n",
        "                chunk_overlap=100,\n",
        "                length_function=len,\n",
        "                is_separator_regex=False,\n",
        "            )\n",
        "            chunks = text_splitter.split_documents(raw_documents)\n",
        "            print (\"Document Split Complete\",filename)\n",
        "            uuids = [str(uuid4()) for _ in range(len(chunks))]\n",
        "            vector_store.add_documents(documents=chunks, ids=uuids)\n",
        "            print(f\"Added file: {filename}\")\n",
        "\n",
        "    # Find deleted files\n",
        "    deleted_files = stored_files - current_files\n",
        "    for filename in deleted_files:\n",
        "        if filename.endswith(\".pdf\"):\n",
        "            filepath = os.path.join(DATA_PATH, filename)\n",
        "            # Find document IDs associated with the deleted file\n",
        "            results = vector_store._collection.get(\n",
        "                where={\"source\": filepath}, include=[\"ids\"]\n",
        "            )\n",
        "            if \"ids\" in results:\n",
        "                ids_to_delete = results[\"ids\"]\n",
        "                vector_store._collection.delete(ids=ids_to_delete)\n",
        "                print(f\"Deleted file: {filename}\")\n",
        "\n",
        "\n",
        "def run_periodic_check():\n",
        "    \"\"\"\n",
        "    Runs the periodic file check in a notebook environment.\n",
        "    \"\"\"\n",
        "    embeddings_model = SentenceTransformerEmbeddings(model_name=\"all-mpnet-base-v2\")\n",
        "    vector_store = Chroma(\n",
        "        collection_name=\"example_collection\",\n",
        "        embedding_function=embeddings_model,\n",
        "        persist_directory=CHROMA_PATH,\n",
        "    )\n",
        "    process_files(vector_store, embeddings_model)\n",
        "    # while False:\n",
        "    #     process_files(vector_store, embeddings_model)\n",
        "    #     time.sleep(interval_seconds)\n",
        "    #     print(f\"Checked for file changes. Next check in {interval_seconds} seconds...\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current_files: {'Nonviolent Communication_ A Language of Life_ Life-Changing Tools for Healthy Relationships ( PDFDrive ).pdf', '.DS_Store', 'AttentionIsAllyouNeed.pdf'}\n",
            "stored_files: {'AttentionIsAllyouNeed.pdf'}\n",
            "Document Split Complete Nonviolent Communication_ A Language of Life_ Life-Changing Tools for Healthy Relationships ( PDFDrive ).pdf\n",
            "Added file: Nonviolent Communication_ A Language of Life_ Life-Changing Tools for Healthy Relationships ( PDFDrive ).pdf\n"
          ]
        }
      ],
      "source": [
        "# To start the periodic check in your notebook, call this function:\n",
        "run_periodic_check()\n",
        "\n",
        "# To stop the check, you'll need to interrupt the kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDm6XjgWrjou"
      },
      "outputs": [],
      "source": [
        "# # Load the embedding model\n",
        "# embeddings_model = SentenceTransformerEmbeddings(model_name=\"all-mpnet-base-v2\")\n",
        "\n",
        "# # Use the model with LangChain as before\n",
        "# vector_store = Chroma(\n",
        "#     collection_name=\"example_collection\",\n",
        "#     embedding_function=embeddings_model,\n",
        "#     persist_directory=CHROMA_PATH,\n",
        "# )\n",
        "\n",
        "# # loading the PDF document\n",
        "# raw_documents = []\n",
        "# for filename in os.listdir(DATA_PATH):\n",
        "#     if filename.endswith(\".pdf\"):\n",
        "#         filepath = os.path.join(DATA_PATH, filename)\n",
        "#         loader = PyPDFLoader(filepath)\n",
        "#         raw_documents.extend(loader.load())\n",
        "\n",
        "# # splitting the document\n",
        "# text_splitter = RecursiveCharacterTextSplitter(\n",
        "#     chunk_size=300,\n",
        "#     chunk_overlap=100,\n",
        "#     length_function=len,\n",
        "#     is_separator_regex=False,\n",
        "# )\n",
        "\n",
        "# # creating the chunks\n",
        "# chunks = text_splitter.split_documents(raw_documents)\n",
        "\n",
        "# # creating unique ID's\n",
        "# uuids = [str(uuid4()) for _ in range(len(chunks))]\n",
        "\n",
        "# # adding chunks to vector store\n",
        "# vector_store.add_documents(documents=chunks, ids=uuids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuB7nzPpEl48",
        "outputId": "e8b7af67-c0b5-4d7d-d243-b1f65e5548c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'dict'>\n",
            "('data/Nonviolent Communication_ A Language of Life_ Life-Changing Tools for Healthy Relationships ( PDFDrive ).pdf', '22')\n"
          ]
        }
      ],
      "source": [
        "num_results = 5\n",
        "\n",
        "retriever = vector_store.as_retriever(search_kwargs={'k': num_results})\n",
        "\n",
        "docs = retriever.invoke(\"What is communication\")\n",
        "print(type(docs[0].metadata))\n",
        "print((docs[0].metadata[\"source\"], docs[0].metadata[\"page_label\"]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dev",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
